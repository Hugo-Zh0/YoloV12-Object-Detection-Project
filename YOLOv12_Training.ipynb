{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hugo-Zh0/YoloV12-Object-Detection-Project/blob/main/YOLOv12_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980016c5",
      "metadata": {
        "id": "980016c5"
      },
      "source": [
        "\n",
        "# üöÄ YOLOv12 Object Detection Project\n",
        "\n",
        "[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/downloads/)\n",
        "[![Anaconda](https://img.shields.io/badge/Anaconda-Navigator-green.svg)](https://www.anaconda.com/download)\n",
        "[![VS Code](https://img.shields.io/badge/Editor-VS%20Code-blue.svg)](https://code.visualstudio.com/)\n",
        "[![Ultralytics](https://img.shields.io/badge/YOLOv12-Ultralytics-yellow.svg)](https://github.com/ultralytics/ultralytics)\n",
        "[![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)](LICENSE)\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "## üìå Overview\n",
        "A **collaborative group project** by Swinburne University students in partnership with **CSIRO**.  \n",
        "This repository contains the setup, configuration, and workflow for training and running **YOLOv12** object detection models.\n",
        "\n",
        "**üë®‚Äçüíª Team Members:** Harron, Feng, Bunmi, Huss, Hugo.\n",
        "\n",
        "---\n",
        "**Repo:** `Hugo-Zh0/YoloV12-Object-Detection-Project`  \n",
        "**What you‚Äôll do:**\n",
        "1. Check runtime & GPU\n",
        "2. Install dependencies\n",
        "3. Clone your repo\n",
        "4. Set paths in repository\n",
        "5. Train\n",
        "6. Validate\n",
        "7. Predict\n",
        "8. Export\n",
        "10. Troubleshoot\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **What to do after completion or if you don't want to run anymore**\n",
        "\n",
        "After completing this colab you will need to export the folders(step 9) which includes the repository and runs, as the runtime session will expire when you close the website **(meaning the folders gets deleted)**.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Starting from previous session**\n",
        "\n",
        "If you are rerunning this agin, you will need to manually upload the folders back into the google colab againn (it has to be zipped up first to be uploaded)\n",
        "Then you will need to run script to extract the folders back to original state.\n",
        "\n",
        "From there you can start from Step 1,2,5,6,7,8 (excludes 3-4 as no need to clone repository and setting paths again)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e32974",
      "metadata": {
        "id": "24e32974"
      },
      "source": [
        "## **Step 1 ‚Äî üöÄ Runtime & GPU check**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prerequistes**\n",
        "*   Change runtime type to T4-GPU\n",
        "*   Change runtime to Python 3\n",
        "*   Have your dataset already downloaded\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AWLh059BB0LN"
      },
      "id": "AWLh059BB0LN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada53746",
      "metadata": {
        "id": "ada53746"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Check Python, CUDA, and PyTorch (Checks if runtime is all correct)\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print(\"PyTorch not installed yet (will install in next step).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cbf86a",
      "metadata": {
        "id": "d0cbf86a"
      },
      "source": [
        "## Step 2 ‚Äî ‚¨áÔ∏è Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0d0331",
      "metadata": {
        "id": "7d0d0331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ba714ef0-6da7-471f-df35-96d91bece26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.186-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.186-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.16-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.186 ultralytics-thop-2.0.16\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Ultralytics: 8.3.186\n",
            "Torch: 2.8.0+cu126 | CUDA: True\n",
            "OpenCV: 4.12.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Install Ultralytics & helpers\n",
        "!pip install ultralytics\n",
        "\n",
        "import torch, cv2, ultralytics\n",
        "print(\"Ultralytics:\", ultralytics.__version__)\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
        "print(\"OpenCV:\", cv2.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a3d181",
      "metadata": {
        "id": "66a3d181"
      },
      "source": [
        "## Step 3 ‚Äî  ü§ñ Clone your repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc02da07",
      "metadata": {
        "id": "bc02da07"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Clone repository from github\n",
        "REPO_URL = \"https://github.com/Hugo-Zh0/YoloV12-Object-Detection-Project\"\n",
        "REPO_DIR = \"/content/YoloV12-Object-Detection-Project\"\n",
        "\n",
        "import shutil, os, pathlib\n",
        "if os.path.isdir(REPO_DIR):\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "!git clone -q {REPO_URL} {REPO_DIR}\n",
        "print(\"Cloned into:\", REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 - Creating folders\n",
        "Next we will need to manually create two folders under our cloned repository\n",
        "* datasets\n",
        "* yaml\n",
        "\n",
        "Datasets:\n",
        "* Folder will store our annotated datasets from roboflow\n",
        "\n",
        "Yaml:\n",
        "\n",
        "* Folder stores our yaml file from our dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XHIlM3roXAfi"
      },
      "id": "XHIlM3roXAfi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 - Import Datset Zip File into Colab"
      ],
      "metadata": {
        "id": "TfgU6SE-DkIQ"
      },
      "id": "TfgU6SE-DkIQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload the ZIP file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "mvVa8CPeECeq"
      },
      "id": "mvVa8CPeECeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip Dataset and save to dataset folder\n",
        "!unzip -q /content/koala.zip -d /content/YoloV12-Object-Detection-Project/datasets/koala\n",
        "#!unzip -q /content/kangaroo.zip -d /content/YoloV12-Object-Detection-Project/datasets/kangaroo"
      ],
      "metadata": {
        "id": "gIpVYqfaR0zt"
      },
      "id": "gIpVYqfaR0zt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0c20f512",
      "metadata": {
        "id": "0c20f512"
      },
      "source": [
        "## Step 4 ‚Äî üéûÔ∏è Set model & data paths"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4.1**\n",
        "\n",
        "Manually move YAML File stored in extracted dataset folder to previously created YAML Folder."
      ],
      "metadata": {
        "id": "-6szwNbvFeF4"
      },
      "id": "-6szwNbvFeF4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4.2**\n",
        "\n",
        "Update the YAML File with proper location paths for: train, val, test\n",
        "\n",
        "Double click the yaml file and it will open on the side.\n",
        "\n",
        "**Koala:**\n",
        "\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/train/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/valid/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/test/images\n",
        "\n",
        "\n",
        "**Kangaroo:**\n",
        "\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/train/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/valid/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/test/images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Finally save the file doinng Ctrl+S"
      ],
      "metadata": {
        "id": "_hWZ-cXcTWxo"
      },
      "id": "_hWZ-cXcTWxo"
    },
    {
      "cell_type": "markdown",
      "id": "b513b46d",
      "metadata": {
        "id": "b513b46d"
      },
      "source": [
        "## Step 5 ‚Äî üí• Train (set your parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11cd1e01",
      "metadata": {
        "id": "11cd1e01"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch, os, sys, requests\n",
        "\n",
        "# --- Direct paths (edit to your repo mount point in Colab) ---\n",
        "MODELS_DIR  = \"/content/YoloV12-Object-Detection-Project/models\"\n",
        "MODEL_PATH  = os.path.join(MODELS_DIR, \"yolo12s.pt\")\n",
        "DATA_YAML   = \"/content/YoloV12-Object-Detection-Project/yaml/data.yaml\"\n",
        "RUNS_DIR    = \"/content/YoloV12-Object-Detection-Project/runs/completed-training\"\n",
        "\n",
        "print(\"Model path:\", MODEL_PATH)\n",
        "print(\"Data yaml :\", DATA_YAML)\n",
        "\n",
        "# Device selection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load your local weights explicitly\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# Train without fetching any other checkpoints\n",
        "results = model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=5,\n",
        "    imgsz=512,\n",
        "    batch=12,\n",
        "    workers=0,\n",
        "    device=device,\n",
        "    pretrained=False,\n",
        "    amp=False,\n",
        "    project=RUNS_DIR,\n",
        "    name=\"train\"\n",
        ")\n",
        "\n",
        "print(\"Save dir:\", results.save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68932001",
      "metadata": {
        "id": "68932001"
      },
      "source": [
        "## Step 6 ‚Äî ‚úÖ Validate best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f59c93e",
      "metadata": {
        "id": "4f59c93e"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Validate best.pt\n",
        "# from pathlib import Path\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# RUNS_DIR = Path(\"/content/runs/detect/completed-training/\") #change the train folder to latest/best training\n",
        "# assert RUNS_DIR.exists(), \"No training runs found. Train first.\"\n",
        "\n",
        "# latest = sorted(RUNS_DIR.glob(\"**/\"), key=lambda p: p.stat().st_mtime)[-1]\n",
        "# best = latest / \"weights\" / \"best.pt\"\n",
        "# print(\"Using:\", best)\n",
        "# assert best.exists(), f\"Missing best.pt in {latest}/weights\"\n",
        "\n",
        "# model = YOLO(str(best))\n",
        "# metrics = model.val(data=str(DATA_YAML), imgsz=512, device=\"cuda\" if __import__(\"torch\").cuda.is_available() else \"cpu\")\n",
        "# print(metrics)\n",
        "\n",
        "# Validate ALL runs under completed-training/, pick best, copy+rename best.pt\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torch, yaml, re, shutil\n",
        "\n",
        "# --- Paths ---\n",
        "DATA_YAML = \"/content/YoloV12-Object-Detection-Project/yaml/data.yaml\"\n",
        "RUNS_ROOT = Path(\"/content/YoloV12-Object-Detection-Project/runs/completed-training\")\n",
        "DEST_DIR  = Path(\"/content/YoloV12-Object-Detection-Project/models\")\n",
        "IMG_SIZE  = 512\n",
        "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "assert RUNS_ROOT.exists(), f\"Missing runs dir: {RUNS_ROOT}\"\n",
        "\n",
        "# Derive dataset slug (e.g., 'koala'/'kangaroo') from data.yaml -> train path\n",
        "with open(DATA_YAML, \"r\") as f:\n",
        "    data_cfg = yaml.safe_load(f)\n",
        "train_path = Path(str(data_cfg.get(\"train\", \"\")))\n",
        "dataset_slug = (train_path.parent.parent.name or \"datasets\") if len(train_path.parts) >= 3 else \"datasets\"\n",
        "\n",
        "# Collect run dirs that have weights/best.pt\n",
        "run_dirs = [d for d in RUNS_ROOT.iterdir() if d.is_dir() and (d / \"weights\" / \"best.pt\").exists()]\n",
        "assert run_dirs, f\"No runs with weights/best.pt under {RUNS_ROOT}\"\n",
        "\n",
        "# Validate each\n",
        "records = []\n",
        "for run in sorted(run_dirs, key=lambda p: p.stat().st_mtime):\n",
        "    best_path = run / \"weights\" / \"best.pt\"\n",
        "    model = YOLO(str(best_path))\n",
        "    metrics = model.val(data=DATA_YAML, imgsz=IMG_SIZE, device=DEVICE, verbose=False)\n",
        "    mAP   = float(getattr(metrics.box, \"map\", 0.0))      # mAP@0.50:0.95\n",
        "    mAP50 = float(getattr(metrics.box, \"map50\", 0.0))    # mAP@0.50\n",
        "    m = re.search(r\"train(\\d+)\", run.name)\n",
        "    run_num = m.group(1) if m else \"\"\n",
        "    records.append({\"run\": run, \"run_num\": run_num, \"best_path\": best_path, \"map\": mAP, \"map50\": mAP50})\n",
        "\n",
        "# Pick best (by mAP50-95, then mAP50)\n",
        "records.sort(key=lambda r: (r[\"map\"], r[\"map50\"]), reverse=True)\n",
        "winner = records[0]\n",
        "\n",
        "# Copy + rename\n",
        "DEST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "new_name = f\"train{winner['run_num']}-{dataset_slug}-best.pt\" if winner[\"run_num\"] else f\"{winner['run'].name}-{dataset_slug}-best.pt\"\n",
        "out_path = DEST_DIR / new_name\n",
        "shutil.copy2(winner[\"best_path\"], out_path)\n",
        "\n",
        "# Summary\n",
        "print(\"Evaluated runs:\")\n",
        "for r in records:\n",
        "    print(f\"- {r['run'].name:>8}: mAP50-95={r['map']:.4f} | mAP50={r['map50']:.4f}\")\n",
        "print(f\"\\nSelected: {winner['run'].name}  ‚Üí  {out_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9401666",
      "metadata": {
        "id": "b9401666"
      },
      "source": [
        "## Step 7 ‚Äî üîÆ Predict (images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea59f46",
      "metadata": {
        "id": "9ea59f46"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Upload images and predict\n",
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "uploaded = files.upload()\n",
        "img_paths = list(uploaded.keys())\n",
        "print(\"Uploaded:\", img_paths)\n",
        "\n",
        "# choose model: latest best or repo weights\n",
        "RUNS_DIR = Path(\"/content/YoloV12-Object-Detection-Project/runs/completed-training/\")\n",
        "best_path = None\n",
        "if RUNS_DIR.exists():\n",
        "    cands = sorted(RUNS_DIR.glob(\"**/weights/best.pt\"), key=lambda p: p.stat().st_mtime)\n",
        "    if cands:\n",
        "        best_path = str(cands[-1])\n",
        "model_path = best_path if best_path else str(Path(\"/content/YoloV12-Object-Detection-Project\") / \"models\" / \"yolo12s.pt\")\n",
        "\n",
        "model = YOLO(model_path)\n",
        "pred = model.predict(source=img_paths, imgsz=512, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save=True)\n",
        "print(\"Saved to:\", pred[0].save_dir if isinstance(pred, list) and pred else \"Check /content/YoloV12-Object-Detection-Project/runs/completed-predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d323b1e",
      "metadata": {
        "id": "1d323b1e"
      },
      "source": [
        "## Step 8 ‚Äî üì∫ Predict (video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c872d2",
      "metadata": {
        "id": "57c872d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Predict on a video (URL or upload)\n",
        "video_url = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "import urllib.request, os\n",
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "src = None\n",
        "if video_url.strip():\n",
        "    src = \"/content/YoloV12-Object-Detection-Project/testing\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(video_url, src)\n",
        "        print(\"Downloaded:\", src)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to download:\", e)\n",
        "        src = None\n",
        "\n",
        "if not src:\n",
        "    up = files.upload()\n",
        "    if up:\n",
        "        src = list(up.keys())[0]\n",
        "        print(\"Uploaded:\", src)\n",
        "\n",
        "assert src, \"No video provided.\"\n",
        "\n",
        "RUNS_DIR = Path(\"/content/YoloV12-Object-Detection-Project/runs/completed-training/trainxxx\")\n",
        "best_path = None\n",
        "if RUNS_DIR.exists():\n",
        "    cands = sorted(RUNS_DIR.glob(\"**/weights/best.pt\"), key=lambda p: p.stat().st_mtime)\n",
        "    if cands:\n",
        "        best_path = str(cands[-1])\n",
        "model_path = best_path if best_path else str(Path(\"/content/YoloV12-Object-Detection-Project\") / \"models\" / \"yolov12s.pt\")\n",
        "\n",
        "model = YOLO(model_path)\n",
        "pred = model.predict(source=src, imgsz=512, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save=True)\n",
        "print(\"Video predictions saved to:\", pred[0].save_dir if isinstance(pred, list) and pred else \"Check /content/YoloV12-Object-Detection-Project/runs/completed-predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7247239",
      "metadata": {
        "id": "c7247239"
      },
      "source": [
        "## Step 9 ‚Äî ‚ôüÔ∏è Exporting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the directory so you don't lose your folders and work."
      ],
      "metadata": {
        "id": "vZOLpRM1HUST"
      },
      "id": "vZOLpRM1HUST"
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Compress the folder into a ZIP file\n",
        "shutil.make_archive('runs', 'zip', '/content/runs')\n",
        "shutil.make_archive('YoloV12-Object-Detection-Project', 'zip', '/content/YoloV12-Object-Detection-Project')\n",
        "\n",
        "# Download the ZIP file\n",
        "from google.colab import files\n",
        "files.download('runs.zip')\n",
        "files.download('YoloV12-Object-Detection-Project.zip')"
      ],
      "metadata": {
        "id": "1Xpk9w4J8kCe"
      },
      "id": "1Xpk9w4J8kCe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67cee5d",
      "metadata": {
        "id": "f67cee5d"
      },
      "outputs": [],
      "source": [
        "## This will become a script to export as a ready model file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b4bd4d",
      "metadata": {
        "id": "00b4bd4d"
      },
      "source": [
        "## Troubleshooting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f7a69d",
      "metadata": {
        "id": "35f7a69d"
      },
      "source": [
        "\n",
        "- **Weights YAML missing:** ensure `models/yolov12s.pt` and `yaml/data.yaml` exist in the repo or update paths.\n",
        "- **No GPU:** Colab may not offer a GPU; the notebook will use CPU (much slower).\n",
        "- **Val fails:** Train first; then rerun the validate cell.\n",
        "- **Poor metrics:** Add more data, correct labels, tune `imgsz`/`batch`/`epochs`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}