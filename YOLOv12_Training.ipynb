{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hugo-Zh0/YoloV12-Object-Detection-Project/blob/main/YOLOv12_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980016c5",
      "metadata": {
        "id": "980016c5"
      },
      "source": [
        "\n",
        "# üöÄ YOLOv12 Object Detection Project\n",
        "\n",
        "[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/downloads/)\n",
        "[![Anaconda](https://img.shields.io/badge/Anaconda-Navigator-green.svg)](https://www.anaconda.com/download)\n",
        "[![VS Code](https://img.shields.io/badge/Editor-VS%20Code-blue.svg)](https://code.visualstudio.com/)\n",
        "[![Ultralytics](https://img.shields.io/badge/YOLOv12-Ultralytics-yellow.svg)](https://github.com/ultralytics/ultralytics)\n",
        "[![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)](LICENSE)\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "## üìå Overview\n",
        "A **collaborative group project** by Swinburne University students in partnership with **CSIRO**.  \n",
        "This repository contains the setup, configuration, and workflow for training and running **YOLOv12** object detection models.\n",
        "\n",
        "**üë®‚Äçüíª Team Members:** Harron, Feng, Bunmi, Huss, Hugo.\n",
        "\n",
        "---\n",
        "**Repo:** `Hugo-Zh0/YoloV12-Object-Detection-Project`  \n",
        "**What you‚Äôll do:**\n",
        "1. Check runtime & GPU\n",
        "2. Install dependencies\n",
        "3. Clone your repo\n",
        "4. Set paths in repository\n",
        "5. Train\n",
        "6. Validate\n",
        "7. Predict\n",
        "8. Export\n",
        "10. Troubleshoot\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Full Process Run Through**\n",
        "\n",
        "Process 1: Train > Validate > Inference > (repeat steps) to get multiple models with different results\n",
        "\n",
        "Processs 2: Run Final Model > Gets Final Model > Run Full Test\n",
        "\n",
        "Process 3: Final Model > Export Model (for deployment)\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **What to do after completion or if you don't want to run anymore**\n",
        "\n",
        "After completing this colab you will need to export the folders(step 9) which includes the repository and runs, as the runtime session will expire when you close the website **(meaning the folders gets deleted)**.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Starting from previous session**\n",
        "\n",
        "If you are rerunning this agin, you will need to manually upload the folders back into the google colab again (it has to be zipped up first to be uploaded)\n",
        "Then you will need to run script to extract the folders back to original state.\n",
        "\n",
        "From there you can start from Step 1,2,5,6,7,8 (excludes 3-4 as no need to clone repository and setting paths again)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e32974",
      "metadata": {
        "id": "24e32974"
      },
      "source": [
        "## **Step 1 ‚Äî üöÄ Runtime & GPU check**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prerequistes**\n",
        "*   Change runtime type to T4-GPU\n",
        "*   Change runtime to Python 3\n",
        "*   Have your dataset already downloaded\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AWLh059BB0LN"
      },
      "id": "AWLh059BB0LN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada53746",
      "metadata": {
        "id": "ada53746"
      },
      "outputs": [],
      "source": [
        "#@title Check Python, CUDA, and PyTorch (Checks if runtime is all correct)\n",
        "\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print(\"PyTorch not installed yet (will install in next step).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cbf86a",
      "metadata": {
        "id": "d0cbf86a"
      },
      "source": [
        "## Step 2 ‚Äî ‚¨áÔ∏è Install dependencies\n",
        "\n",
        "These are the python libraries and Ultralytics libraries needed to run the framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0d0331",
      "metadata": {
        "id": "7d0d0331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ba714ef0-6da7-471f-df35-96d91bece26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.186-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.186-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.16-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.186 ultralytics-thop-2.0.16\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Ultralytics: 8.3.186\n",
            "Torch: 2.8.0+cu126 | CUDA: True\n",
            "OpenCV: 4.12.0\n"
          ]
        }
      ],
      "source": [
        "#@title Install Ultralytics & helpers\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "import torch, cv2, ultralytics\n",
        "print(\"Ultralytics:\", ultralytics.__version__)\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
        "print(\"OpenCV:\", cv2.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a3d181",
      "metadata": {
        "id": "66a3d181"
      },
      "source": [
        "## Step 3 ‚Äî  ü§ñ Clone your repository\n",
        "\n",
        "Grabs our repository which contains our folder structure/files and folders to get started with our training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc02da07",
      "metadata": {
        "id": "bc02da07"
      },
      "outputs": [],
      "source": [
        "#@title Clone repository from github\n",
        "\n",
        "REPO_URL = \"https://github.com/Hugo-Zh0/YoloV12-Object-Detection-Project\"\n",
        "REPO_DIR = \"/content/YoloV12-Object-Detection-Project\"\n",
        "\n",
        "import shutil, os, pathlib\n",
        "if os.path.isdir(REPO_DIR):\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "!git clone -q {REPO_URL} {REPO_DIR}\n",
        "print(\"Cloned into:\", REPO_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 - Creating folders\n",
        "Next we will need to manually create two folders under our cloned repository\n",
        "* datasets\n",
        "* yaml\n",
        "\n",
        "Datasets:\n",
        "* Folder will store our annotated datasets from roboflow\n",
        "\n",
        "Yaml:\n",
        "\n",
        "* Folder stores our yaml file from our dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XHIlM3roXAfi"
      },
      "id": "XHIlM3roXAfi"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Datset Zip File into Colab\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "mvVa8CPeECeq"
      },
      "id": "mvVa8CPeECeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip Dataset and save to dataset folder\n",
        "\n",
        "# for koala (comment if using kangaroo)\n",
        "!unzip -q /content/koala.zip -d /content/YoloV12-Object-Detection-Project/datasets/koala\n",
        "\n",
        "# for kangaroo (uncomment if using kangaroo)\n",
        "#!unzip -q /content/kangaroo.zip -d /content/YoloV12-Object-Detection-Project/datasets/kangaroo"
      ],
      "metadata": {
        "id": "gIpVYqfaR0zt"
      },
      "id": "gIpVYqfaR0zt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0c20f512",
      "metadata": {
        "id": "0c20f512"
      },
      "source": [
        "## Step 4 ‚Äî üéûÔ∏è Set model & data paths"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4.1**\n",
        "\n",
        "Manually move YAML File stored in extracted dataset folder to previously created YAML Folder."
      ],
      "metadata": {
        "id": "-6szwNbvFeF4"
      },
      "id": "-6szwNbvFeF4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4.2**\n",
        "\n",
        "Update the YAML File with proper location paths for: train, val, test\n",
        "\n",
        "Double click the yaml file and it will open on the side.\n",
        "\n",
        "**Koala:**\n",
        "\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/train/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/valid/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/koala/test/images\n",
        "\n",
        "\n",
        "**Kangaroo:**\n",
        "\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/train/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/valid/images\n",
        "* /content/YoloV12-Object-Detection-Project/datasets/kangaroo/test/images\n",
        "\n",
        "<br>\n",
        "\n",
        "Finally save the file doing Ctrl+S"
      ],
      "metadata": {
        "id": "_hWZ-cXcTWxo"
      },
      "id": "_hWZ-cXcTWxo"
    },
    {
      "cell_type": "markdown",
      "id": "b513b46d",
      "metadata": {
        "id": "b513b46d"
      },
      "source": [
        "## Step 5 ‚Äî üí• Train (set your parameters)\n",
        "\n",
        "This script will train your dataset and store them in the respoitory locations.\n",
        "You can also set the configs you want to train your dataset, tune it however you like to get the best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11cd1e01",
      "metadata": {
        "id": "11cd1e01"
      },
      "outputs": [],
      "source": [
        "#@title Set Configs and train datasaet\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch, os, sys, requests\n",
        "\n",
        "# Direct paths to locations\n",
        "MODELS_DIR  = \"/content/YoloV12-Object-Detection-Project/models\"\n",
        "MODEL_PATH  = os.path.join(MODELS_DIR, \"yolo12s.pt\")\n",
        "DATA_YAML   = \"/content/YoloV12-Object-Detection-Project/yaml/data.yaml\"\n",
        "RUNS_DIR    = \"/content/YoloV12-Object-Detection-Project/runs/completed-training\"\n",
        "\n",
        "print(\"Model path:\", MODEL_PATH)\n",
        "print(\"Data yaml :\", DATA_YAML)\n",
        "\n",
        "# Device selection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load your local weights explicitly\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# Training configs (leave imgsz as 640) everything else change change\n",
        "results = model.train(\n",
        "    data=DATA_YAML, # refers to our dataset yaml file\n",
        "    epochs=150,\n",
        "    imgsz=640,\n",
        "    batch=-1,\n",
        "    workers=2,\n",
        "    device=device,\n",
        "    pretrained=False,\n",
        "    amp=False,\n",
        "    project=RUNS_DIR,\n",
        "    name=\"train\"\n",
        ")\n",
        "\n",
        "print(\"Save dir:\", results.save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68932001",
      "metadata": {
        "id": "68932001"
      },
      "source": [
        "## Step 6 ‚Äî ‚úÖ Test latest trained model\n",
        "\n",
        "This script will grab the latest trained runs, uses its best.pt to validate its correct file and do a test on the model to see if detection is happening correctly, looking for accuracy, bounding boxes and efficiency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test latest trained model\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Path where YOLO saves runs\n",
        "RUNS_DIR = \"/content/YoloV12-Object-Detection-Project/runs/completed-training\"\n",
        "\n",
        "# Folder where you want to save validation results\n",
        "RESULTS_DIR = \"/content/YoloV12-Object-Detection-Project/runs/test-results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Find the most recent training run\n",
        "latest_run = max(glob.glob(os.path.join(RUNS_DIR, \"*\")), key=os.path.getmtime)\n",
        "weights_path = os.path.join(latest_run, \"weights\", \"best.pt\")\n",
        "\n",
        "print(f\"Validating latest run: {latest_run}\")\n",
        "print(f\"Using weights: {weights_path}\")\n",
        "\n",
        "# Load the best model from that run\n",
        "model = YOLO(weights_path)\n",
        "\n",
        "# Run validation on the TEST split (change metrics to the same trained metrics used)\n",
        "metrics = model.val(\n",
        "    data=\"DATA_YAML\",\n",
        "    split=\"test\",\n",
        "    imgsz=640,\n",
        "    batch=-1\n",
        ")\n",
        "\n",
        "# Build results filename based on run name (e.g., train2 -> train2_metrics.txt)\n",
        "run_name = os.path.basename(latest_run)\n",
        "save_path = os.path.join(RESULTS_DIR, f\"{run_name}_metrics.txt\")\n",
        "\n",
        "# Save metrics to file\n",
        "with open(save_path, \"w\") as f:\n",
        "    f.write(f\"Validation results for run: {run_name}\\n\")\n",
        "    f.write(f\"Weights: {weights_path}\\n\\n\")\n",
        "    for k, v in metrics.items():\n",
        "        f.write(f\"{k}: {v}\\n\")\n",
        "\n",
        "print(f\"Metrics saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "gx7GByuFmlER"
      },
      "id": "gx7GByuFmlER",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b9401666",
      "metadata": {
        "id": "b9401666"
      },
      "source": [
        "## Step 7 ‚Äî üîÆ Inference Testing For Images And Videos\n",
        "\n",
        "After completeing a model test from step 6, we will move onto testing with new images and videos. Which can be sourced online anywhere. This way testing will be more accurate as its new data that the model hasn't been trained/tested on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create folder to store test images and videos\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/YoloV12-Object-Detection-Project/testing\"\n",
        "folder_name = \"koala\" #change to kangaroo if doing kangaroo dataset\n",
        "target_path = os.path.join(base_dir, folder_name)\n",
        "\n",
        "os.makedirs(target_path, exist_ok=True)\n",
        "print(f\"Folder created at: {target_path}\")\n",
        "\n",
        "# Prompt user to upload files\n",
        "print(\"Please upload your image or video files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files into the target folder\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(target_path, filename))\n",
        "    print(f\"Moved '{filename}' to '{target_path}'.\")\n",
        "\n",
        "print(\"All files uploaded and saved in your custom directory!\")"
      ],
      "metadata": {
        "id": "vT8fCvumrYoT"
      },
      "id": "vT8fCvumrYoT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea59f46",
      "metadata": {
        "id": "9ea59f46"
      },
      "outputs": [],
      "source": [
        "#@title Inference Testing with Images & Videos\n",
        "import glob\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Path where YOLO saves runs\n",
        "RUNS_DIR = \"/content/YoloV12-Object-Detection-Project/runs/completed-training\"\n",
        "\n",
        "# Path to your test folder (contains both images & videos)\n",
        "TEST_DIR = \"/content/YoloV12-Object-Detection-Project/testing/koala\"\n",
        "\n",
        "# Base path for inference results\n",
        "OUTPUT_BASE = os.path.join(TEST_DIR, \"inference_results\")\n",
        "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
        "\n",
        "# Find the next available inference folder (inference1, inference2, ...)\n",
        "i = 1\n",
        "while os.path.exists(os.path.join(OUTPUT_BASE, f\"inference{i}\")):\n",
        "    i += 1\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_BASE, f\"inference{i}\")\n",
        "\n",
        "# Find the most recent training run\n",
        "latest_run = max(glob.glob(os.path.join(RUNS_DIR, \"*\")), key=os.path.getmtime)\n",
        "weights_path = os.path.join(latest_run, \"weights\", \"best.pt\")\n",
        "\n",
        "print(f\"Running inference with weights: {weights_path}\")\n",
        "print(f\"Testing folder: {TEST_DIR}\")\n",
        "print(f\"Results will be saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "# Load model\n",
        "model = YOLO(weights_path)\n",
        "\n",
        "# Run inference (images + videos in same folder)\n",
        "results = model.predict(\n",
        "    source=TEST_DIR,   # folder containing both images & videos\n",
        "    imgsz=640,\n",
        "    conf=0.25,\n",
        "    save=True,\n",
        "    project=OUTPUT_DIR,\n",
        "    name=\"\",           # ensures results are saved directly in OUTPUT_DIR\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(f\"Inference complete. Results saved to: {OUTPUT_DIR}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8 - ü™£ Choosing Final Model for Deployment\n",
        "\n",
        "This step will go through every single trained model/validation results, and finds/selects the best model from the metrics provided. This way with the Final Model selected will go through final inference testing then Step 9 to be exported and used in real world deployment."
      ],
      "metadata": {
        "id": "qx8cT_NBzOj4"
      },
      "id": "qx8cT_NBzOj4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f59c93e",
      "metadata": {
        "id": "4f59c93e"
      },
      "outputs": [],
      "source": [
        "#@title Find the best final model to use from test results (saves as a csv)\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Paths\n",
        "RUNS_DIR = \"runs/train\"\n",
        "DATA_YAML = \"DATA_YAML\"  # <-- replace with your dataset yaml path\n",
        "RESULTS_DIR = \"/content/YoloV12-Object-Detection-Project/runs/model-results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)  # make sure dir exists\n",
        "\n",
        "# Output CSV path\n",
        "CSV_PATH = os.path.join(RESULTS_DIR, \"model_comparison.csv\")\n",
        "\n",
        "results_list = []\n",
        "\n",
        "# Loop through all training runs\n",
        "for run in sorted(glob.glob(os.path.join(RUNS_DIR, \"*\"))):\n",
        "    weights_path = os.path.join(run, \"weights\", \"best.pt\")\n",
        "    if not os.path.exists(weights_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Validating {run} ...\")\n",
        "    model = YOLO(weights_path)\n",
        "    metrics = model.val(data=DATA_YAML, split=\"test\", imgsz=640, batch=-1)\n",
        "\n",
        "    results_list.append({\n",
        "        \"run\": os.path.basename(run),\n",
        "        \"weights\": weights_path,\n",
        "        \"mAP50\": metrics.box.map50,\n",
        "        \"mAP50-95\": metrics.box.map,\n",
        "        \"precision\": metrics.box.mp,\n",
        "        \"recall\": metrics.box.mr\n",
        "    })\n",
        "\n",
        "# Save results to CSV\n",
        "df = pd.DataFrame(results_list)\n",
        "df.to_csv(CSV_PATH, index=False)\n",
        "\n",
        "print(f\"\\nModel comparison saved to {CSV_PATH}\")\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compares Model Metrics in CSV and chooses the best model\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# ==== CONFIG ====\n",
        "CSV_PATH = \"/content/YoloV12-Object-Detection-Project/runs/model-results/model_comparison.csv\"\n",
        "MODELS_DIR = \"/content/YoloV12-Object-Detection-Project/models\"\n",
        "SUMMARY_DIR = \"/content/YoloV12-Object-Detection-Project/model-resuslts\"\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(SUMMARY_DIR, exist_ok=True)\n",
        "\n",
        "# loads csv file\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# checks csv columns (correct data)\n",
        "required_cols = {\"run\", \"weights\", \"mAP50-95\", \"mAP50\", \"precision\", \"recall\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"CSV missing required columns: {missing}\")\n",
        "\n",
        "for c in [\"mAP50-95\", \"mAP50\", \"precision\", \"recall\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# picks best model from csv data metrics\n",
        "best_row = df.sort_values(\n",
        "    by=[\"mAP50-95\", \"mAP50\", \"precision\"],  # tie-break if needed\n",
        "    ascending=[False, False, False]\n",
        ").iloc[0]\n",
        "\n",
        "run = best_row[\"run\"]\n",
        "src = best_row[\"weights\"]\n",
        "\n",
        "if not isinstance(src, str) or not os.path.exists(src):\n",
        "    raise FileNotFoundError(f\"best.pt not found: {src}\")\n",
        "\n",
        "# Destination name: trainxxx_best.pt\n",
        "base_name = f\"{run}_best.pt\"\n",
        "dst = os.path.join(MODELS_DIR, base_name)\n",
        "\n",
        "print(f\"   Best model found: {run}\")\n",
        "print(f\"   mAP50-95: {best_row['mAP50-95']:.4f} | mAP50: {best_row['mAP50']:.4f} | precision: {best_row['precision']:.4f}\")\n",
        "print(f\"   Copying: {src} -> {dst}\")\n",
        "\n",
        "shutil.copy2(src, dst)\n",
        "\n",
        "# Output and saving summary selection\n",
        "summary_csv = os.path.join(SUMMARY_DIR, \"best_model_summary.csv\")\n",
        "best_row.to_frame().T.to_csv(summary_csv, index=False)\n",
        "print(f\"\\n Summary written to: {summary_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6Z8CLSip2NHr"
      },
      "id": "6Z8CLSip2NHr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c7247239",
      "metadata": {
        "id": "c7247239"
      },
      "source": [
        "## Step 9 ‚Äî ‚ôüÔ∏è Exporting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the full respository incase you run into errors, you think the runtime is about to expire or you just want to save it to run later on."
      ],
      "metadata": {
        "id": "vZOLpRM1HUST"
      },
      "id": "vZOLpRM1HUST"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export Repository as Zip File\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive('YoloV12-Object-Detection-Project', 'zip', '/content/YoloV12-Object-Detection-Project')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('YoloV12-Object-Detection-Project.zip')"
      ],
      "metadata": {
        "id": "1Xpk9w4J8kCe"
      },
      "id": "1Xpk9w4J8kCe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67cee5d",
      "metadata": {
        "id": "f67cee5d"
      },
      "outputs": [],
      "source": [
        "## This will become a script to export as a ready model file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b4bd4d",
      "metadata": {
        "id": "00b4bd4d"
      },
      "source": [
        "## Troubleshooting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f7a69d",
      "metadata": {
        "id": "35f7a69d"
      },
      "source": [
        "\n",
        "- **Weights YAML missing:** ensure `models/yolo12s.pt` and `yaml/data.yaml` exist in the repo or update paths.\n",
        "- **Val fails:** Train first; then rerun the validate cell.\n",
        "- **Poor metrics:** Add more data, correct labels, tune `imgsz`/`batch`/`epochs`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}